{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection - Tensorflow Models\n",
    "- code reference taken from - https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/plot_object_detection_saved_model.html#sphx-glr-auto-examples-plot-object-detection-saved-model-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "import bbox_visualizer as bbv\n",
    "#img_bbox = bbv.draw_rectangle(img_arr, [427, 347, 1278, 672])\n",
    "\n",
    "import pandas as pd\n",
    "import image_preprocessing_library as lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Name List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = [\n",
    "    #('efficientdet_d0_coco17_tpu-32', '20200711'), # done\n",
    "    #('efficientdet_d7_coco17_tpu-32', '20200711') #done\n",
    "    #('ssd_mobilenet_v2_320x320_coco17_tpu-8', '20200711'), #done\n",
    "    #('ssd_resnet50_v1_fpn_640x640_coco17_tpu-8', '20200711') #done\n",
    "    #('faster_rcnn_resnet50_v1_640x640_coco17_tpu-8', '20200711'), #done\n",
    "    ('faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8', '20200711')\n",
    "    #('ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8', '20200711'), #done\n",
    "    #('mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8', '20200711'), #some error, needs to be solved first, https://github.com/tensorflow/models/issues/9255\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"../../../dataset/object_detection/images\")\n",
    "detection_result_path = Path(\"../experiment_results/final_results/\")\n",
    "df_columns = [\"image_name\", \"label\", \"detection_score\", \"ymin\", \"xmin\", \"ymax\", \"xmax\", \"model_name\", \"processing_seq_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8\"\n",
    "#model_name = \"efficientdet_d0_coco17_tpu-32\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the COCO Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_labels(filename):\n",
    "    base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n",
    "    label_dir = tf.keras.utils.get_file(fname=filename,\n",
    "                                        origin=base_url + filename,\n",
    "                                        untar=False)\n",
    "    label_dir = pathlib.Path(label_dir)\n",
    "    return str(label_dir)\n",
    "\n",
    "LABEL_FILENAME = 'mscoco_label_map.pbtxt'\n",
    "PATH_TO_LABELS = download_labels(LABEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shubham\\\\.keras\\\\datasets\\\\mscoco_label_map.pbtxt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load label map data (for plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processing_seq_dict = {\n",
    "#     \"seq_0\" : [], # for raw seq\n",
    "#     \"seq_1\" : [\"gray\"],\n",
    "#     \"seq_2\" : [\"hsv\"],\n",
    "#     \"seq_3\" : [\"sharpen\"],\n",
    "#     \"seq_4\" : [\"gray\", \"bilateral_blur\", \"threshold_mean\"],\n",
    "#     \"seq_5\" : [\"gray\", \"bilateral_blur\", \"threshold_gaussian\"],\n",
    "#     \"seq_6\" : [\"gray\", \"bilateral_blur\", \"threshold_otsu\"],\n",
    "#     \"seq_7\" : [\"median_blur\"],\n",
    "    \"seq_8\" : [\"gaussian_blur\"],\n",
    "    \"seq_9\" : [\"bilateral_blur\"],\n",
    "    \"seq_10\" : [\"fastnl_blur\"],\n",
    "    \"seq_11\" : [\"gray\", \"bilateral_blur\", \"threshold_otsu\", \"opening\"],\n",
    "    \"seq_12\" : [\"gray\", \"bilateral_blur\", \"threshold_otsu\", \"closing\"],\n",
    "    \"seq_13\" : [\"opening\"],\n",
    "    \"seq_14\" : [\"closing\"],\n",
    "    \"seq_15\" : [\"gray\", \"sobel\"],\n",
    "    \"seq_16\" : [\"gray\", \"laplacian\"],\n",
    "    \"seq_17\" : [\"gray\", \"canny\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model from tensorflow.org/models\n",
    "- More models can be found in the TensorFlow 2 Detection Model Zoo. To use a different model you will need the URL name of the specific model. This can be done as follows:\n",
    "1. Right click on the Model name of the model you would like to use;\n",
    "2. Click on Copy link address to copy the download link of the model;\n",
    "3. Paste the link in a text editor of your choice. You should observe a link similar to download.tensorflow.org/models/object_detection/tf2/YYYYYYYY/XXXXXXXXX.tar.gz;\n",
    "4. Copy the XXXXXXXXX part of the link and use it to replace the value of the MODEL_NAME variable in the code shown below;\n",
    "5. Copy the YYYYYYYY part of the link and use it to replace the value of the MODEL_DATE variable in the code shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8\n"
     ]
    }
   ],
   "source": [
    "# Download and extract model\n",
    "def download_model(model_name, model_date):\n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    model_dir = tf.keras.utils.get_file(fname=model_name,\n",
    "                                        origin=base_url + model_date + '/' + model_file,\n",
    "                                        untar=True)\n",
    "    return str(model_dir)\n",
    "\n",
    "def download_models(model_name_list):\n",
    "    model_dir_path_dict = {}\n",
    "    for model_name in model_name_list:\n",
    "        path = download_model(model_name[0], model_name[1])\n",
    "        model_dir_path_dict[model_name[0]] = path\n",
    "        print(\"downloaded {0}\".format(model_name[0]))\n",
    "    return model_dir_path_dict\n",
    "\n",
    "\n",
    "#use below list to know model name and where it is downloaded locally\n",
    "model_dir_path_dict = download_models(model_name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the downloaded models from directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_batch(batch_size, seq_id):\n",
    "    batch_images = []\n",
    "    counter = 1\n",
    "    for image_name in os.listdir(dataset_path):\n",
    "        img = Image.open(dataset_path/image_name)\n",
    "        #TO-DO : pre run this step of converting to RGB and remove from here\n",
    "        rgb_im = img.convert('RGB')\n",
    "        processed_img = apply_cv_transformations(seq_id, rgb_im)\n",
    "        batch_images.append((image_name, processed_img))\n",
    "        if counter % batch_size == 0:\n",
    "            yield batch_images\n",
    "            batch_images = []\n",
    "        counter = counter + 1\n",
    "\n",
    "def apply_cv_transformations(seq_id, pil_img):\n",
    "    cv_img = convert_to_cv_img(pil_img)\n",
    "    operations = get_seq_operations(seq_id)\n",
    "    processed_img = cv_img\n",
    "    for operation in operations:\n",
    "        processed_img = lib.dispatcher[operation](processed_img)\n",
    "    return convert_to_pil_img(processed_img)         \n",
    "\n",
    "def convert_to_pil_img(opencv_img):\n",
    "    if opencv_img.dtype == 'float64':\n",
    "        opencv_img = opencv_img.astype(np.uint8)\n",
    "    pil_img = cv2.cvtColor(opencv_img, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(pil_img)\n",
    "    return pil_img\n",
    "\n",
    "def convert_to_cv_img(pil_img):\n",
    "    np_img_arr = np.asarray(pil_img)\n",
    "    cv_image=cv2.cvtColor(np_img_arr, cv2.COLOR_RGB2BGR)\n",
    "    return cv_image\n",
    "\n",
    "def get_seq_operations(seq_id):\n",
    "    return pre_processing_seq_dict[seq_id]\n",
    "\n",
    "def get_seq_name(seq_id):\n",
    "    if seq_id not in pre_processing_seq_dict.keys():\n",
    "        return \"not found for dataset id: \" + seq_id\n",
    "    return \" > \".join(get_seq_operations(seq_id))\n",
    "\n",
    "def load_model(model_name, model_dir):\n",
    "    print(model_dir)\n",
    "    path_to_saved_model = model_dir + \"/saved_model\"\n",
    "\n",
    "    print('Loading model...', end='')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load saved model and build the detection function\n",
    "    detect_fn = tf.saved_model.load(path_to_saved_model)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Done! Took {} seconds'.format(elapsed_time))\n",
    "    return detect_fn\n",
    "\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "def detect_objects(model, pil_images_tuple):\n",
    "    #works on single image\n",
    "    # use Image.fromarray(image_np) for converting below numpy arr img to pil img\n",
    "    detections_list = []\n",
    "    for pil_img_tuple in pil_images_tuple:\n",
    "        image_np = np.array(pil_img_tuple[1])\n",
    "\n",
    "        # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "        input_tensor = tf.convert_to_tensor(image_np)\n",
    "        # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "        input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "        # input_tensor = np.expand_dims(image_np, 0)\n",
    "        detections = model(input_tensor)\n",
    "        detections_list.append((pil_img_tuple[0], detections))\n",
    "    return detections_list\n",
    "\n",
    "def process_detections(detections_tuple_list):\n",
    "    # works on list of detections\n",
    "    processed_detections_list = []\n",
    "    for detections_tuple in detections_tuple_list:\n",
    "        detections = detections_tuple[1]\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy()\n",
    "                       for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "\n",
    "        # detection_classes should be ints.\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "        processed_detections_list.append((detections_tuple[0], detections))\n",
    "    return processed_detections_list\n",
    "\n",
    "def visualise_results(detections, image_np, use_normalized_coordinates=True):\n",
    "    # detections - single image detection result from a model, this detection object should be from the model inference result\n",
    "    # image_np - numpy image\n",
    "    # visualise single image results\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    # detection box - ymin, xmin, ymax, xmax\n",
    "    # denormalise using - (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    \n",
    "    pil_img = Image.fromarray(image_np_with_detections)\n",
    "    width, height = pil_img.size\n",
    "    print(\"before vis shape \", end='')\n",
    "    print(width, height)\n",
    "    \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=use_normalized_coordinates,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.50,\n",
    "          agnostic_mode=False)\n",
    "    \n",
    "    #plt.figure()\n",
    "    \n",
    "    pil_img = Image.fromarray(image_np_with_detections)\n",
    "    width, height = pil_img.size\n",
    "    print(\"after vis shape \", end='')\n",
    "    print(width, height)\n",
    "    \n",
    "    plt.imshow(image_np_with_detections)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(image_name, batch_img_tuple):\n",
    "    # returns the image size by searching image_name in batch_img_tuple\n",
    "    # input: image_name:\"xyz\", batch_img_tuple: [(img_name, pil_img)]\n",
    "    # returns - (width, height)\n",
    "    return [tup[1] for tup in batch_img_tuple if tup[0] == image_name][0].size\n",
    "    \n",
    "def denormalise_boxes(img_size, boxes):\n",
    "    # returns the normalised boxx coordinates - (ymin, xmin, ymax, xmax)\n",
    "    # img_size: (width, height), boxes - [[coordinates]...]\n",
    "    denorm_boxes = []\n",
    "    width, height = img_size\n",
    "    for box in boxes:\n",
    "        temp = []\n",
    "        temp.append(box[0]*height)\n",
    "        temp.append(box[1]*width)\n",
    "        temp.append(box[2]*height)\n",
    "        temp.append(box[3]*width)\n",
    "        denorm_boxes.append(temp)\n",
    "    return np.array(denorm_boxes)\n",
    "\n",
    "def filter_detections(detections_list, batch_images, denorm = True):\n",
    "    # purpose - filter passed detections based on threshold, and denormalise box coordinates\n",
    "    # input - [(image_name, {boxes, scores, classes, ...})]\n",
    "    # output - [(image_name, {boxes, scores, classes})]\n",
    "    filtered_detection_list = []\n",
    "    for detection_tuple in detections_list:\n",
    "        filtered_dict = {}\n",
    "        image_name = detection_tuple[0]\n",
    "        detections = detection_tuple[1]\n",
    "        \n",
    "        scores = detections[\"detection_scores\"]\n",
    "        #scores = [score for score in scores if score > 0.0]\n",
    "        scores = scores[:100] #take only 100\n",
    "        take = len(scores)\n",
    "\n",
    "        boxes = detections[\"detection_boxes\"]\n",
    "        boxes = boxes[: take]\n",
    "        \n",
    "        if denorm:\n",
    "            #denormalise boxes\n",
    "            img_size = get_image_size(image_name, batch_images)\n",
    "            boxes = denormalise_boxes(img_size, boxes)\n",
    "\n",
    "        classes = detections[\"detection_classes\"]\n",
    "        classes = classes[: take]\n",
    "        \n",
    "        filtered_dict[\"detection_scores\"] = scores\n",
    "        filtered_dict[\"detection_boxes\"] = boxes\n",
    "        filtered_dict[\"detection_classes\"] = classes\n",
    "        \n",
    "        filtered_detection_list.append((image_name, filtered_dict))\n",
    "    return filtered_detection_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, images_tuple):\n",
    "    detections_list = detect_objects(model, images_tuple)\n",
    "    detections_list = process_detections(detections_list)\n",
    "    \n",
    "    # process detections object to output list as per your need\n",
    "    # below method will filter out the boxes based on threshold and also denormalise the coordinates.\n",
    "    detections_list = filter_detections(detections_list, images_tuple)\n",
    "    return detections_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_name(label_id):\n",
    "    if label_id not in category_index.keys():\n",
    "        return \"NA\"\n",
    "    return category_index[label_id][\"name\"]\n",
    "\n",
    "def prepare_per_image_res(detection_res):\n",
    "    # detection_res: (image_name, {detection_scores:[], detection_boxes:array(), detection_classes:array()})\n",
    "    num_detections_per_image = len(detection_res[1][\"detection_boxes\"])\n",
    "    rows = []\n",
    "    for i in range(0, num_detections_per_image):\n",
    "        image_name = detection_res[0]\n",
    "        label_id = detection_res[1][\"detection_classes\"][i]\n",
    "        label = get_label_name(label_id)\n",
    "        box = detection_res[1][\"detection_boxes\"][i]\n",
    "        score = round(detection_res[1][\"detection_scores\"][i], 2)\n",
    "        row = [image_name, label, score, int(box[0]), int(box[1]), int(box[2]), int(box[3])]\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def store_results(detection_results, pre_processing_seq_name):\n",
    "    # process detection_results for storing it in the df/csv\n",
    "    #     round of the bbox coordinates\n",
    "    df_rows = []\n",
    "    for res in detection_results:\n",
    "        rows = prepare_per_image_res(res)\n",
    "        df_rows.extend(rows)\n",
    "            \n",
    "    # append model_name, seq_name at the end of rows\n",
    "    info = [model_name, pre_processing_seq_name]\n",
    "    for row in df_rows:\n",
    "        row.extend(info)\n",
    "    \n",
    "    # create a df for storing the results\n",
    "    df = pd.DataFrame(df_rows, columns = df_columns)\n",
    "    \n",
    "    # check if csv file exists, if yes then append result, if not the create and dump the result\n",
    "    if not os.path.exists(detection_result_path/(model_name + \".csv\")):\n",
    "        # store the df in to model_name.csv file\n",
    "        df.to_csv(detection_result_path/(model_name + \".csv\"), index=False)\n",
    "    else:\n",
    "        stored_df = pd.read_csv(detection_result_path/(model_name + \".csv\"))\n",
    "        stored_df = stored_df.append(df)\n",
    "        stored_df.to_csv(detection_result_path/(model_name + \".csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubham\\.keras\\datasets\\faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8\n",
      "Loading model...Done! Took 101.96210312843323 seconds\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_name, model_dir_path_dict[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing for seq_id:seq_8 started.\n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...----------------\n",
      "processing for seq_id:seq_9 started.\n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...----------------\n",
      "processing for seq_id:seq_10 started.\n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...----------------\n",
      "processing for seq_id:seq_11 started.\n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...----------------\n",
      "processing for seq_id:seq_12 started.\n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...----------------\n",
      "processing for seq_id:seq_13 started.\n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...----------------\n",
      "processing for seq_id:seq_14 started.\n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...----------------\n",
      "processing for seq_id:seq_15 started.\n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...----------------\n",
      "processing for seq_id:seq_16 started.\n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...----------------\n",
      "processing for seq_id:seq_17 started.\n",
      "1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...----------------\n",
      "Inference completed for model:faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8\n"
     ]
    }
   ],
   "source": [
    "for seq_id in pre_processing_seq_dict.keys():\n",
    "    print(\"processing for seq_id:{0} started.\".format(seq_id))\n",
    "    counter = 1\n",
    "    for batch_images in load_images_batch(50, seq_id):\n",
    "        print(\"{0}\".format(counter), end=\"...\")\n",
    "        detection_result = run_inference(model, batch_images)\n",
    "        store_results(detection_result, seq_id)\n",
    "        counter = counter + 1\n",
    "    print(\"----------------\")\n",
    "print(\"Inference completed for model:{0}\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEQ 7 completed, run from seq 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
